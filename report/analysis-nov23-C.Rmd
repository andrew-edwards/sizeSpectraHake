---
title: "Analyses of hake lengths using size spectra approach -- nov23 data, just strata C"
author: "Andrew Edwards"
output: pdf_document
fontsize: 12pt
date: "Last compiled on `r format(Sys.time(), '%d %B, %Y')`"
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "",
  fig.width = 10,
  fig.height = 8
)
```

```{r, packages}
library(dplyr)
library(sizeSpectra)    # Probably need latest version
library(pacea)          # Need for hake_recruitment_over_2010 which cannot be exported
if(!"sizeSpectraHake" %in% (.packages())){
  load_all()      # Obviously update manually if updated package
}
```

## Load wrangled data

This is what should be changed for each analysis. `orig` or `nov23` and `C` or
`all_strata`. Comment one in each pair of these first four lines. And change the
filename and title. Though probably not going to back to `orig` data, since have
moved on considerably, and `nov23` data stream will be the one to be extended
going forward.
```{r load}
# dataset <- "orig"
dataset <- "nov23"

strata_to_analyse <- "C"
# strata_to_analyse <- c("C", "NC", "S", "SC", "N")    # equals strata_to_keep;
                                                       # may want to do more individually
# If add anything else need to change this_analysis below and min_year_to_analyse
# North to south:
# WA, OR, N (north), NC (north central), C (core), SC (south central), S
# (south); see Figure 1 of Santora et al. 2021.

# Do these explicitly so consistent to add future ones. (Or make a paste0 version.
if(dataset == "orig"){
  stop("Code from this commit on won't work for this")
  raw_simp_prop <- readRDS("raw_simp_prop_orig.rds")
  bin_width_each_year <- readRDS("bin_width_each_year_orig.rds")
}

if(dataset == "nov23"){
  raw_simp_prop <- readRDS("raw_simp_prop_nov23_sets_resolution.rds")
  counts_full <- readRDS("counts_nov23")
}

# What to append to filenames for anything we're saving; not changing object
# names within this analysis
this_analysis <- ifelse(strata_to_analyse == "C",
                        paste0(dataset, "_C"),
                        paste0(dataset, "_all_strata"))

# Automatically get right start year, may need tweaking. Max year default is
# last year of data.
min_year_to_analyse <- ifelse(strata_to_analyse == "C",
                              1994,
                              2001)      # data look okay but Iain had said 2004 for
                                         # all strata, so check TODO
# TODO see if don't need that, expect min should be in data anyway once filtered
# strata C. Come back to.

# TODO temporary to figure out 10-mm issue. Come back to.
# min_year_to_analyse <- 2006 #2014 #NULL  #2004
max_year_to_analyse <- NULL #2006 #2014# NULL  # 2004
```

## Do analysis and plot results

These arguments shouldn't need changing. See end of file for caption. Do the
analysis (this chunk is **CACHED**):

Copying cached directories as `...before-resolving-10mm` before changing code.



Now do the data preparation first, maybe no need to functionalise. TODO check
thinking about `min_wmin_to_consider_10_mm` being 25. No other way to do it.
```{r dataprep}
# Minima to cut off -- using these later when split the data into 1 mm and 10 mm
# to plot basic histograms. Or could maybe just go with 25 as the min, keep life easy
# - and since poorly sampled there should be fine for lower cut off. Partly avoid
# figuring out the 25-35 mm bin issue.
min_wmin_to_consider <- 27.5
min_wmin_to_consider_1_mm <- 25  # 27.5 is what Iain had said; trying 25 for
                                 # simplicity now, and will want that in
                                 # plots. Will visually check that mode is not < 27.5
min_wmin_to_consider_10_mm <- 25 # next lowest multiple of 5 that isn't a
                                 # multiple of 10; started writign
                                 # next_big_bin_down() but just do manually.
max_wmax_to_consider_1_mm <- 89.5  # 89.5 is what Iain had said; trying 95 for
                                 # simplicity now
max_wmax_to_consider_10_mm <- 95 # next highest multiple of 5 that isn't a
                                 # multiple of 10

counts_full

# Need to get into format for dataBinForLike in negLL.PLB.bins.species, with
# year to loop over that

counts_per_bin_per_set_id <- summarise(group_by(counts_full,
                                                id_set,
                                                wmin),    # wmin will work for 1 mm and 10mm
                                       # because id_set distinguishes
                                       year = unique(year),
                                       strata = unique(strata),
                                       resolution = unique(resolution),
                                       number = sum(binCount),
                                       wmin = unique(wmin),
                                       wmax = unique(wmax),
                                       id = unique(id)) %>% # makes the 2-set hauls easier
  filter(strata %in% strata_to_analyse) %>%
  relocate(id_set,
           wmin,
           wmax,
           number,
           resolution,
           year,     # Keep these last three but move them out of the way
           strata,
           id) %>%
  ungroup()

counts_per_bin_per_set_id
summary(counts_per_bin_per_set_id)
```

### Can we split up first 10-mm bin based on the first overlapping 10-mm bins?

Now fit one year. First tried 1994 and resulting $b$ matched MLEbin, but there
is no 10-mm issue there. So now try 2001:
```{r oneyear}
one_year = 2001
counts_per_bin_per_set_id_one_year <- filter(counts_per_bin_per_set_id,
                                  year == one_year)
```

Now work out `xmin` based on 1-mm bin counts.
```{r xmincalc}
counts_per_bin_pre_apportion_one_year <- summarise(group_by(counts_per_bin_per_set_id_one_year,
                                                   wmin,
                                                   resolution),
                                          number = sum(number),
                                          wmax = unique(wmax)) %>%
  arrange(resolution,
          wmin) %>%
  relocate(wmin,
           wmax,
           number,
           resolution) %>%
  ungroup()

# When functionalise, then do if statement here and only do the apportion for
# years with no 10-mm bins at all. TODO. For now just testing with 2001.

counts_per_bin_1_mm_one_year <- filter(counts_per_bin_pre_apportion_one_year,
                                       resolution == 1,
                                       wmin >= min_wmin_to_consider_1_mm - 0.001,
                                       wmax <= max_wmax_to_consider_1_mm + 0.001)
counts_per_bin_1_mm_one_year %>% a()

xmin <- determine_xmin(counts_per_bin_1_mm_one_year)

stopifnot("Need to think about min wmin and xmin" = xmin >= min_wmin_to_consider)
# Apportion 10-mm bins based on xmin, note that includes all wmin for 1-mm
# because can't just ignore the ones in [min_wmin_to_consider_1_mm, xmin].
counts_per_bin_per_set_id_one_year_apportioned <-
  apportion_10_mm_bin_all_hauls(counts_per_bin_per_set_id_one_year,
                                xmin)

```

```{r function10mmbin}
# output will be counts_per_bin_10_mm_apportioned - same as counts_per_bin_10_mm
# but with the bin that contains xmin appropriately apportioned, to then use in
# plots and then combine with 1-mm data to do the fitting.
# apportion_10_mm_bin() actually goes below into the loop
```

```{r step77}
counts_per_bin_10_mm_per_set_id_one_year_apportioned <- filter(
  counts_per_bin_per_set_id_one_year_apportioned,
  resolution == 10,
  wmin >= min_wmin_to_consider_10_mm - 0.001,
  wmax <= max_wmax_to_consider_10_mm + 0.001)

counts_per_bin_10_mm_per_set_id_one_year_apportioned %>% a()

# Now sum to give just the new bins (as done above for
# counts_per_bin_pre_apportion), that will replace the existing one in
# counts_per_bin_pre_apportion; though easier just to bind with
#  counts_per_bin_1_mm_one_year
counts_per_bin_10_mm_one_year_apportioned <- summarise(
  group_by(
    counts_per_bin_10_mm_per_set_id_one_year_apportioned,
    wmin,
    resolution),  # should only be 10 anyway, but keep as a check
  number = sum(number),
  wmax = unique(wmax)) %>%
  arrange(resolution,
          wmin) %>%
  relocate(wmin,
           wmax,
           number,
           resolution) %>%
  ungroup()

counts_per_bin_10_mm_one_year_apportioned %>% a()
```

Then need to bind them, first just check we have the same total number as we
started with, for 10-mm bins.

```{r checknumber}
# Sum of 'number' should match number here, to ensure have kept the same numbers
orig <- filter(counts_per_bin_per_set_id_one_year,
               resolution == 10,
               wmin >= min_wmin_to_consider_10_mm - 0.001,
               wmax <= max_wmax_to_consider_10_mm + 0.001)

expect_equal(sum(orig$number),
             sum(counts_per_bin_10_mm_one_year_apportioned$number))

expect_equal(sum(orig$number),
             sum(counts_per_bin_10_mm_per_set_id_one_year_apportioned$number))
```

Now combine the 1-mm and 10-mm values. Do need to keep the 1-mm bins below
`xmin` but above `min_wmin_to_consider_10_mm`, but not use them for fitting
(have a check earlier that `xmin >= min_wmin_to_consider_1_mm`. Will figure out
what to do if the opposite happens.

```{r combinecounts}
counts_per_bin_one_year <- bind_rows(counts_per_bin_1_mm_one_year,
                                     counts_per_bin_10_mm_one_year_apportioned)
counts_per_bin_one_year %>% a()

```

For 10-mm, use the unapportioned values for plotting basic histograms, since
have to adapt `make_hist()` and plotting to use the apportioned one. MLEbins
plot will use apportioned, so don't want to spend a lot of time on the fix
now. TODO at somepoint.

```{r checksomething}
counts_per_bin_10_mm_one_year_unapportioned <- filter(counts_per_bin_pre_apportion_one_year,
                                       resolution == 10,
                                       wmin >= min_wmin_to_consider_10_mm - 0.001,
                                       wmax <= max_wmax_to_consider_10_mm + 0.001)
counts_per_bin_10_mm_one_year_unapportioned %>% a()


# Then can plot the histograms:
make_hist_1_mm <- make_hist(counts_per_bin_1_mm_one_year)  # adapted function to be able
                                        # to use  wmin, wmax etc (as for MLEbins).
make_hist_10_mm_unapportioned <- make_hist(counts_per_bin_10_mm_one_year_unapportioned,
                                           bin_width = 10)    # TODO adapt
                                             # function to use the
                                        # bin_width specified maybe, and the
                                        # apportioned values. Get an
                                        # error as mids are not multiples of bin_width

xlim_hist <- c(min_wmin_to_consider_10_mm,
              max_wmax_to_consider_10_mm)
par(mfrow = c(2,1))
plot(make_hist_1_mm,
     main = one_year,
     xlim = xlim_hist)
plot(make_hist_10_mm_unapportioned,
     main = one_year,
     xlim = xlim_hist)
```

## Fitting the ISD

```{r fits}
# TODO - need this when looping over years
## vecDiff_use <- ifelse(years_to_analyse[i] == 2006 &
##                       strata_to_analyse == "C",
##                       200,
##                       15)   # TODO add dataset == "nov23"  also, need to
##                                 # input into function

## Need to use
## MLEbins and see vignette. But 1994 has none of those, summary(counts_per_bin_per_set_id_one_year)
## and correctly gave the same answer as MLEbin. So then make loop to go over years here, then
## maybe make a function (might not be worth it, easier here to dig into
## things), then have to figure out hist figure - first just use 1-mm bins for
## it. Idea on walk was to overlay the 10-mm bins in different colour, hope they
## don't make much difference to picking xmin. First try 2001 as that has clear
## 10mm issue.

counts_per_bin_one_year_desc <- filter(counts_per_bin_one_year,
                                       wmin >= xmin)

n = sum(counts_per_bin_one_year_desc$number)
# xmin = min(counts_per_bin_desc$wmin) # done earlier
xmax = max(counts_per_bin_one_year_desc$wmax)

# Need to change resolution to specCode for this. Make a function maybe.
# And number to Number

counts_per_bin_one_year_desc_rename <- counts_per_bin_one_year_desc %>%
  rename(Number = number,
         specCode = resolution)

MLEbins_one_year <- calcLike(negLL.fn = negLL.PLB.bins.species,
                             p = -1.9,
                             suppress.warnings = FALSE,
                             dataBinForLike = counts_per_bin_one_year_desc_rename,
                             n = n,
                             xmin = xmin,
                             xmax = xmax,
                             vecDiff = 1)   # had 15 in vecDiff_use but taking
                                        # forever, and that was for MLEbin
MLEbins_one_year
# 1994: woo-hoo, matches analysis-nov23-C-before-resolving-10mm.pdf
# 2001: MLEbins here gives b=-6.71, MLEbin gave -6.79. Wow, tiny change. Prob
# wider confidence intervals here I expect.
# 2008 should have bigger difference
```

HERE HERE HERE -- need to write a function to get the cumulative counts worked
out, it's kind of buried in `ISD_bin_plot_nonoverlapping()` but I need to use
`ISD_bin_plot()` for which I did it in the vignette.

Single plot (adapting from `plot.hake_spectra_results()` but should parse that
out into individual functions probably.
```{r plotoneyear}
counts_per_bin_one_year_desc_rename_2  <- counts_per_bin_one_year_desc_rename %>%
                 rename(binCount = Number) # Not enough, need >= counts etc.
sizeSpectra::ISD_bin_plot(
               binValsTibble = counts_per_bin_one_year_desc_rename_2,
               b.MLE = MLEbins_one_year$b_l,
               b.confMin = MLEbins_one_year$conf[1],
               b.confMax = MLEbins_one_year$conf[2],
               yBig.inc = 10000,
               xLab = "Body length (x), mm",
               year = one_year)
               # xlim = xlim_global,


```


```{r fitallyearsfunction, cache = FALSE, eval = FALSE}
res_all_years <- fit_all_years(raw_simp_prop,
                               strata_to_analyse = strata_to_analyse,
                               bin_width_each_year = bin_width_each_year,
                               min_year_to_analyse = min_year_to_analyse,
                               max_year_to_analyse = max_year_to_analyse)   # TODO temporary,
                                        # needs removing. (One year Some years were

MLEbin_res_all_years <- MLEbin_results_extract(res_all_years)  # tibble of
                                        # annual results

# plot(res_all_years, par.cex = 0.8,) in next chunk but not echoed
```

\clearpage

NOT LOOKING AT HERE ONWARDS
Not evaluating:
```{r, plotall, fig.pos = 'p', fig.height = 6.9, echo=FALSE, eval=FALSE}
plot(res_all_years)
#     par.cex = 0.8,)    # For ISD plot
```

## NEED TO DO FOR EACH ANALYSIS TYPE.... go through ISD plots to decide which years should be excluded

### 10 mm resolution

Clearly some years have some of the data recorded at 10 mm resolution instead of
1 mm. John had mentioned this: "the PWCC/NWFSC data (mostly OR/WA data 2001-2009) only has measurements to the nearest cm.  Long story, but that is what they recorded (NWC was leading that effort, ".

Look into 2004 raw data more carefully. Be good to get the 2004 out of these
names, or definitely make a function TODO. 13/12/23: 2004 now looks okay,
thought still a 10-mm issue; worse for other years.

EXPLORATORY:

```{r raw2004}
raw_2004 <- filter(raw_simp_prop,
                   year == 2004,
                   strata %in% strata_to_analyse)
raw_2004
summary(raw_2004)
# filter(raw_2004, prop_measured < 0.01) %>% as.data.frame()

filter(raw_2004, x == 30) %>% select(-"strata")

# Vector of measured lengths that aren't multiples of 10 mm
non_10_mm_measurements_2014 <- unique(raw_2004$x)[unique(raw_2004$x) %% 10 > 0] %>% sort()

non_10_mm_measurements_2014

# ids which do not have non-10-mm measurements; i.e. only have 10 mm ones (the
# 1-mm ids can still have some 10-mm measurements)
ids_with_mm_accuracy_2014 <- filter(raw_2004,
                               x %in% non_10_mm_measurements_2014)$id %>%
                                                            unique()
raw_with_10_mm_only_2014 <- filter(raw_2004,
                              !(id %in% ids_with_mm_accuracy_2014))
raw_with_10_mm_only_2014 %>% a()

ids_with_10_mm_only_2014 <- unique(raw_with_10_mm_only_2014$id)

ids_with_10_mm_only_2014

sum(raw_with_10_mm_only_2014$scaled_counts)

sum(raw_2004$scaled_counts)
# So the 10-mm only don't seem to be the bulk of the measurements, the latter (I
# think) is what I'd expected. Have assumed that if measuring to 10 mm then doing that for the
# whole id (haul).
```

So redo analysis for 2004, excluding the 10-mm only hauls.

```{r fitallyears2004excl}
raw_simp_prop_2004_excl <- filter(raw_simp_prop,
                                  id %in% ids_with_mm_accuracy_2014)

# raw_2004 above already did strata
expect_equal(raw_simp_prop_2004_excl, filter(raw_2004, id %in%
                                                       ids_with_mm_accuracy_2014))

res_2004_excl <- fit_all_years(raw_simp_prop_2004_excl,
                               strata_to_analyse = strata_to_analyse,
                               bin_width_each_year = bin_width_each_year,
                               min_year_to_analyse = 2004,
                               max_year_to_analyse = 2004)   # TODO temporary,
                                        # needs removing. (One year Some years were

MLEbin_res_2004_excl <- MLEbin_results_extract(res_2004_excl)
```

\clearpage

```{r, plot2004excl, fig.pos = 'p', fig.height = 6.9, echo=FALSE}
plot(res_2004_excl, par.cex = 0.8)
```

## Checking data are what I thought

Was confused as to what data are, but it was me. This should
clarify. `number_measured` should be per haul, so check that:

```{r rawsimp2004exclsumm2}
raw_simp_prop_2004_excl %>%
  #  select(-c("year", "strata")) %>%
  group_by(id) %>%
  summarise(id = unique(id),
            number_of_rows = n(),
            number_measured = unique(number_measured)) %>%
  mutate(measured_is_more = (number_measured >= number_of_rows)) %>%
  a()

```

Had done this, but in the original spreadsheet, lines 15964-15968 has 5 rows for
2004 haul 36 strata C (as does the saved `hake83to2023lengths.csv`, but my code only has one:
```{r rawsimp200436C}
filter(raw_simp_prop, id == "2004_C_36")
```

So something wrong with my data wrangling somewhere. Need to hunt backwards.


This helped me come up with the question above.

```{r rawsimp2004exclsumm}
# So first 5 make sense, but if 6th one (different haul) has 5 measured what are the other measurements?
raw_simp_prop_2004_excl %>%
  select(-c("year", "strata")) %>%
  filter(total_no ==  5) %>%
  a()

# Similarly here, only 11 measurements not 23 (all the same haul):
raw_simp_prop_2004_excl %>%
  select(-c("year", "strata")) %>%
  filter(total_no ==  23) %>%
  a()
```


## Realised can actually do that for all years in one go

Had redone the above for 2016 which has no 10-mm only hauls (so verifying the
code works for such years), then realised can just do all years in one go.

```{r non10mmallyears}
raw_simp_prop_strata <- filter(raw_simp_prop,
                               strata %in% strata_to_analyse)

# Vector of measured lengths that aren't multiples of 10 mm
non_10_mm_measurements <-
  unique(raw_simp_prop_strata$x)[unique(raw_simp_prop_strata$x) %% 10 > 0] %>%
  sort()

non_10_mm_measurements

# ids which do not have non-10-mm measurements; i.e. only have 10 mm ones (the
# 1-mm ids can still have some 10-mm measurements)
ids_with_mm_accuracy <- filter(raw_simp_prop_strata,
                               x %in% non_10_mm_measurements)$id %>%
                        unique()

raw_with_10_mm_only <- filter(raw_simp_prop_strata,
                              !(id %in% ids_with_mm_accuracy))
raw_with_10_mm_only

summary(raw_with_10_mm_only)

ids_with_10_mm_only <- unique(raw_with_10_mm_only$id)

ids_with_10_mm_only

sum(raw_with_10_mm_only$scaled_counts)

sum(raw_simp_prop_strata$scaled_counts)

sum(raw_with_10_mm_only$scaled_counts) / sum(raw_simp_prop_strata$scaled_counts)

# So the 10-mm only don't seem to be the bulk of the measurements, the latter (I
# think) is what I'd expected. Have assumed that if measuring to 10 mm then doing that for the
# whole id (haul). Still 5%, more than I was thinking.

# Need to check how many measurements there are for each of these id.
haul_with_10_mm_only <-
  raw_with_10_mm_only %>%
  group_by(id) %>%
  summarise(year = unique(year),
            "10_mm_only_per_haul" = n())

haul_with_10_mm_only %>% a()

```

Can see no hauls before 2000


 - think about the above. Looks good, and makes sense. Can keep ones
that have 1 or 2 with 10-mm only, but 2001-2009 look like they indeed are the
only years that need dealing with.

## Going through histograms and ISD plots - nov23 and strata C

So go through the histograms and ISD plots, checking outliers and 'rounded to 10
mm' type issues, and taking into account sample size `n`. Comment below on
each year (with exclude if warranted, else include):

1994 - good fit, could look at sensitivity to largest fish (causes 62-cm bin to
be stretched out on log-log plot, though that bin does have more than expected)

1995 - good fit

1996 - good fit, though unusual in that all >50 cm are more frequent than
expected from PLB

1997 - fairly good fit

1998 - fairly good, with two 'unexpected' large fish; could test sensitivity,
but no good reason to exclude them

1999 - fairly good fit, but looks like a blip at 60-cm that might be affecting
it slightly, and doesn't really fit in with nearby bins (perhaps because it's
including 55-60?).

2000 - good fit, but larger are less than expected

2001- 2004 definitely a 10-mm issue going on currently, exclude for now TODO look into

2005 - $n=15$, maybe even less were actually measured, exclude

2006 - $n=6$, maybe even less were actually measured, exclude

2007-2009 - 10-mm issue TODO, exclude

2010 - good fit, 67 and 74 look a bit large - maybe check the scaling up of those

2011 - great fit, though very possible 10-mm issue TODO

2012 - kind of good fit though strange gap before large set of sizes, lots of
similar frequencies implying similar scaling up; look into data in a bit more detail

2013 - fairly good fit

2014 - slightly unusual fit, with a bit of a hump, possible 10-mm issue but only
with 60-mm?

2015 - fairly good fit, but again with 60-mm looking overly common

2016 - very nice fit, $n$ almost 50,000 (TODO though check actual number measured), slightly less than expected in larger classes

2017 - good fit, with one or two outlier 69-mm fish, a lot of 52-mm (but nothing
inbetween)

2018 - goodish fit, with some 'missing' larger sizes

2019 - weird fit because only five bins, because mode is so high - strange one,
exclude (but look into more?) TODO

2020 - $n=10$ so exclude (explains the large confidence intervals in the plot
with it included)

2021 - fairly good, looks like first bin is quite common and may be what's
giving the sharp decline.

2022 - possible 30-mm and 40-mm look high? 10-mm issue? Otherwise a nice fit.

2023 - fairly good fit.

This suggests
excluding analyses for years, for now (TODO fix the 10-mm obvious issues, check
some of them again):
```{r excludeyears}
years_exclude <- c(2001:2009, 2019, 2020, 2021:2023) # TODO adapt plotting
                                        # function to show last years without
# recruitment estimates
# years_exclude <- c(2005:2006, 2019, 2020, 2021:2023) # to look at all except
# obvious ones to miss out
```

TODO histogram for 2006 has only a few values, but still looks different to
original analyses based on La Jolla file (looking at
`hake-lengths-strata-C-all-years.html`); can check when re-reun this file on
orig data. Here, even setting vecDiff to 1000 it didn't fit, as only two
bins. Works for vecDiff = 200, so use that.

## Show the plot for all years and write notes

Now plot the estimated hake recruitments of age-0's for each year against the
corresponding $b_l$, and add the uncertainties.

```{r, plotrecruitments}
plot_b_recruitment(MLEbin_res_all_years,
                   years_exclude = years_exclude)
```

TODO notes not yet for this actual plot.

So, what does this mean. Large recruitment years ($> 20\%$ of the 2010
recruitment) always seem to have a higher $b_l$. Note that 2021 has a long tail
of uncertainty (reaching quite high), but that's because it will have only been
observed in one year of commercial data.

A high $b_l$ seems necessary for high recruitment, but is not sufficient. Kind
of makes sense -- other things can happen during further life-history stages.

But, a low $b_l$ seems to imply low recruitment. This could be a heads up for
advice.

Of course, this may well all fall apart with further analyses, validation, and more
data.

In terms of the assessment done at the start of 2023, we have to assume recruitment
for recruitment in 2022 (which hasn't been observed in data in
the assessment model, but is what we can calculate $b_l$ for, hopefully in a
timely fashion) and 2023 (which are just being spawned while we are doing the
2023 assessment). The assumption is based on the stock recruitment curve with a
large uncertainty, and is shown in blue on the plot.

A look at the values for each year, includes converted $b_w$ value:
```{r MLEbinvalues}
select(MLEbin_res_all_years, -c("b_w_confMin", "b_w_confMax", "b_l_stdErr")) %>%
  a()
```

A quick look at including all years (useful for looking at recent ones that
should be plotted differently TODO):

```{r, plotrecruitmentsexcludenone}
plot_b_recruitment(MLEbin_res_all_years)
```


## Might be useful for analysing

```{r lookatme}
only_2008 <- filter(raw_simp_prop,
                    year == 2008)
filter(only_2008, prop_measured < 0.01) %>% as.data.frame()

only_2014 <- filter(raw_simp_prop,
                    year == 2014)
summary(only_2014)
filter(only_2014, prop_measured < 0.01) %>% as.data.frame()  # none
filter(only_2014, prop_measured < 0.05) %>% as.data.frame()  #

filter(only_2014, x == 70) %>% as.data.frame()   # TODO something coarser also,
                                        # these are lots of SC - so again with
                                        # the coarse measurements. Aha - those
                                        # 70 measurements (the max) should be
                                        # spread out.
filter(only_2014, x == 69) %>% as.data.frame()   # only 5
filter(only_2014, x == 71) %>% as.data.frame()   # only 4

only_2014_C <- filter(only_2014, strata == "C") %>%
  select(-c("year", "strata"))
only_2014_C %>% a()

sum(only_2014_C$scaled_counts)
# = 543.49, but plot using fit_all_years adds up to about 1,000
# copied from `fit_all_years()`

# Not as drastically wrong as 2004, but still different.
bin_width <- 1
counts_per_bin_2014_C <- summarise(group_by(only_2014_C,
                                            x),
                                   binCount = sum(scaled_counts)) %>%
      mutate(binMid = x,         # Assume these are midpoints, but TODO check
             binMin = binMid - bin_width/2,
             binMax = binMid + bin_width/2) %>%
      arrange(binMid) %>%
      select(-"x")

# Copying from fit_all_years to do explicity
if(!expect_equal(min(diff(counts_per_bin_2014_C$binMid)), bin_width)){
      stop(paste0("Double check the value in bin_width_each_year; may have to relax this condition; this failed for year ", years_to_analyse[i]))

      # Having no adjacent bins with values will cause this to fail, which seems
      # unlikely), but would want to manually look into and then tweak
      # condition. Does not fail for 2021 even with 0.01 mm bins.
    }

    max_ind <- which.max(counts_per_bin_2014_C$binCount)

    ifelse(max_ind == 1,
           counts_per_bin_2014_C_desc <- counts_per_bin_2014_C,
           counts_per_bin_2014_C_desc <- counts_per_bin_2014_C[-(1:(max_ind-1)), ])

    MLEbin_res <-  sizeSpectra::calcLike(negLL.fn = sizeSpectra::negLL.PLB.binned,
                                         p = -1.5,
                                         w = c(dplyr::pull(counts_per_bin_2014_C_desc,
                                                           binMin),
                                               dplyr::pull(counts_per_bin_2014_C_desc,
                                                           binMax)[nrow(counts_per_bin_2014_C_desc)]),
                                         # all minima plus max of final bin
                                         d = dplyr::pull(counts_per_bin_2014_C_desc,
                                                         binCount),
                                         J = nrow(counts_per_bin_2014_C_desc),   # = num.bins
                                         # suppress.warnings = TRUE,
                                         vecDiff = 15)             # increase this if hit a bound

# MLEbin_res
# $MLE
# [1] -3.365493
#
#$conf
#[1] -4.317493 -2.434493

# This is different from fit_all_years() result of b=-25
# Try that again:
res_all_years_just_2014_C <- fit_all_years(raw_simp_prop,
                               strata_to_analyse = strata_to_analyse,
                               bin_width_each_year = bin_width_each_year,
                               min_year_to_analyse = 2014,
                               max_year_to_analyse = 2014)

# Gives me the same answer. Something messing with running this .Rmd. Trying it again.
```

## Caption for ISD plot

Caption for ISD plot:

The y-axis is (a) linear and (b) logarithmic. For each bin, the horizontal green
line shows the range of body lengths of that bin, with its value
on the y-axis corresponding to the total number of individuals in bins whose
minima are $\geq$ the bin's minimum. By definition, this includes all individual
in that bin; for example, all $n$ individuals are $\geq$ the minimum of
the first (left-most) bin, so that bin is at $n$ on the y-axis. The vertical
span of each grey rectangle shows the possible numbers of
individuals with body length $\geq$ the
body length of individuals in that bin (horizontal
span is the same as for the green lines). The maximum number of such individuals
is the same as the green line, and the minimum number (bottom of grey rectangle)
is the total number of individuals $\geq$ the bin's maximum. By definition, this is then the
green line for the next bin. This plotting method allows us to properly represent the
discrete binned data on a continuous scale.
The text
in (a) gives the MLE for the length size-spectrum exponent
$b$, and the sample size $n$.

```{r caption}
caption_index <- 1   # index to use for detailed captions
```

TODO (adapting from MEPS vignette; double check the numbers): For example, the first bin is for lengths
between `r res_all_years[[caption_index]]$counts_per_bin_desc$binMin[1]` and `r res_all_years[[caption_index]]$counts_per_bin_desc$binMax[1]` mm, and
countains a count of `r f(res_all_years[[caption_index]]$counts_per_bin_desc$binCount[1])` individuals. We don't know
how those individual's lengths are distributed within the bin. The green line on
the y-axis illustrates that the number of individuals $\geq$ the minimum of the
bin (`r res_all_years[[caption_index]]$counts_per_bin_desc$binMin[1]` mm) is
`r f(sum(res_all_years[[caption_index]]$counts_per_bin_desc$binCount), 1)`, namely
all the individuals because this is the minimum length in the data. The grey
shaded area shows the uncertainty -- the number (on the y-axis) of possible individual individuals with
body mass $\geq$ any x-value within the bin is between
`r f(sum(res_all_years[[caption_index]]$counts_per_bin_desc$binCount) - res_all_years[[caption_index]]$counts_per_bin_desc$binCount[1], 1)`
and
`r f(sum(res_all_years[[caption_index]]$counts_per_bin_desc$binCount), 1)`
(all individuals in the bin could be the smallest
length within the bin or the highest).
